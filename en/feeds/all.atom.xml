<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>kele.github.io</title><link href="http://kele.github.io/en/" rel="alternate"></link><link href="http://kele.github.io/feeds/all.atom.xml" rel="self"></link><id>http://kele.github.io/en/</id><updated>2017-06-18T00:00:00+02:00</updated><entry><title>Proxy server in Rust (part 2)</title><link href="http://kele.github.io/en/proxy-server-in-rust-part-2.html" rel="alternate"></link><published>2017-06-18T00:00:00+02:00</published><updated>2017-06-18T00:00:00+02:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2017-06-18:/en/proxy-server-in-rust-part-2.html</id><summary type="html">&lt;p&gt;First draft and the basics of Rust.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Let's listen over TCP&lt;/h2&gt;
&lt;p&gt;This is how a draft of the main source file looks like (explanations below): &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;// main.rs&lt;/span&gt;

&lt;span class="k"&gt;use&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;::&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PROXY_PORT&lt;/span&gt;: &lt;span class="kt"&gt;u16&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4000&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;listener&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;::&lt;span class="n"&gt;TcpListener&lt;/span&gt;::&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;127.0.0.1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PROXY_PORT&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;match&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;listener&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accept&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;Ok&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;sock&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;handle_connection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sock&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;Err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;panic&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Error while accepting connection: {}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;fn&lt;/span&gt; &lt;span class="nf"&gt;handle_connection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tcp&lt;/span&gt;: &lt;span class="nc"&gt;net&lt;/span&gt;::&lt;span class="n"&gt;TcpStream&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Opened connection: {:?}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tcp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Listening&lt;/h3&gt;
&lt;p&gt;We're going to use &lt;strong&gt;crate&lt;/strong&gt;
&lt;a href="https://doc.rust-lang.org/std/net/"&gt;&lt;code&gt;std::net&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;use&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;::&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href="https://doc.rust-lang.org/std/net/struct.TcpListener.html"&gt;&lt;code&gt;std::net::TcpListener::bind&lt;/code&gt;&lt;/a&gt;
function is used here to start listening on port 4000 of the localhost.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PROXY_PORT&lt;/span&gt;: &lt;span class="kt"&gt;u16&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4000&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="kd"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;listener&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;::&lt;span class="n"&gt;TcpListener&lt;/span&gt;::&lt;span class="n"&gt;bind&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;127.0.0.1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PROXY_PORT&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;&lt;span class="n"&gt;unwrap&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;u16&lt;/code&gt; corresponds to &lt;code&gt;uint16&lt;/code&gt; known from other languages, so &lt;code&gt;const PROXY_PORT:
u16 = 4000;&lt;/code&gt; is a definition of a &lt;code&gt;PROXY_PORT&lt;/code&gt; constant 16-bit integer equal to
4000.&lt;/p&gt;
&lt;p&gt;What about the mysterious &lt;code&gt;unwrap()&lt;/code&gt; at the end? Rust is a language designed
with safety with minimal runtime overhead in mind. How is this achieved in this
case? &lt;code&gt;bind()&lt;/code&gt; could've simply returned &lt;code&gt;TcpListener&lt;/code&gt;, but instead it returns
&lt;a href="https://doc.rust-lang.org/std/io/type.Result.html"&gt;&lt;code&gt;std::io::Result&amp;lt;TcpListener&amp;gt;&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What's the difference?&lt;/p&gt;
&lt;p&gt;Something can go wrong while trying to bind the socket (i.e. the port can be
already in use). This can be handled in many different ways (all with different
trade offs):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;throwing an exception (Java, C++?),&lt;/li&gt;
&lt;li&gt;returning a pointer (C, C++),&lt;/li&gt;
&lt;li&gt;returning two values &lt;code&gt;(TcpListener, bool)&lt;/code&gt; (Go),&lt;/li&gt;
&lt;li&gt;&lt;a href="http://en.cppreference.com/w/cpp/utility/optional"&gt;&lt;code&gt;std::optional&lt;/code&gt;&lt;/a&gt; (C++17).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Throwing an exception does not make the programmer handle it. Retruning a
pointer or a &lt;code&gt;bool&lt;/code&gt; value does not help here either. &lt;code&gt;std::optional&lt;/code&gt; can be
simply ignored using &lt;code&gt;*&lt;/code&gt;. Rust tries to follow a different path. Instead of the
abovementioned solutions, an object is returned in a wrapping (&lt;code&gt;Result&lt;/code&gt;). This
type can be one of the two: the expected value of type &lt;code&gt;TcpListener&lt;/code&gt; or an error
(&lt;code&gt;Error&lt;/code&gt;)!&lt;/p&gt;
&lt;p&gt;Since binding a socket to a port is vital for this program to run, the only
thing I do here is &lt;code&gt;unwrap()&lt;/code&gt; the result.&lt;/p&gt;
&lt;p&gt;What does this method do? If there is no error - the value is returned. If an
error happened, &lt;a href="https://doc.rust-lang.org/std/macro.panic.html"&gt;&lt;code&gt;panic!&lt;/code&gt;&lt;/a&gt; is
called (similar to &lt;a href="https://blog.golang.org/defer-panic-and-recover"&gt;&lt;code&gt;panic&lt;/code&gt;&lt;/a&gt;
known from Go).&lt;/p&gt;
&lt;h3&gt;Accepting a connection&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;match&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;listener&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accept&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;Ok&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;sock&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;handle_connection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sock&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;Err&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;panic&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Error while accepting connection: {}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If everything wen't smoothly, let's call &lt;code&gt;handle_connection(sock)&lt;/code&gt;, which will
take care of the rest.&lt;/p&gt;
&lt;p&gt;If not, &lt;code&gt;panic!&lt;/code&gt; with an appropriate error message.&lt;/p&gt;
&lt;h3&gt;Pattern matching (&lt;code&gt;match&lt;/code&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;match&lt;/code&gt; is a language construct used mostly in functional languages (like
OCaml, Haskell, Lisp) rather than imperative ones (C, Python, Java, C++) and
that's why I'd like to say a few words about it.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Pattern_matching"&gt;&lt;strong&gt;Pattern matching&lt;/strong&gt;&lt;/a&gt; is used
for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;checking whether the object is what we think it is (in the above code, whether
  it's &lt;code&gt;Ok&lt;/code&gt; (value) or &lt;code&gt;Err&lt;/code&gt; (an error)&lt;/li&gt;
&lt;li&gt;dissecting it (&lt;code&gt;Ok&lt;/code&gt; is here made of two parts, the first one is the TCP
  socket, the second is the address; I'm ignoring the adress (using &lt;code&gt;_&lt;/code&gt;), but
  binding the &lt;code&gt;sock&lt;/code&gt; variable to the socket).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For example, if we were to write a simple calculator based on trees of
arithmetic expressions, a part of code might have looked like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;match&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expression&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Mul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;Div&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This language construct is possible thanks to types that are an disjunction of
different possible values. In this case it means that the expression can be i.e.
an addition or substraction. The information about the kind of expression is
stored and retrieved at runtime. What's important is the fact that the compiler
can check whether we've covered all the possible kinds (and warn us if we forget
about one).&lt;/p&gt;
&lt;p&gt;We could've simulated it in C++ in a following way:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;enum&lt;/span&gt; &lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;Add&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Sub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Mul&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Div&lt;/span&gt; &lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;Expression&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;union&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;Add&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;Sub&lt;/span&gt; &lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;Mul&lt;/span&gt; &lt;span class="n"&gt;mul&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
        &lt;span class="n"&gt;Div&lt;/span&gt; &lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;

&lt;span class="k"&gt;switch&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="n"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nl"&gt;Add&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="n"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nl"&gt;Sub&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="n"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nl"&gt;Mul&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="n"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nl"&gt;Div&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, pattern matching is pretty convenient. In the languages that
support it natively, the implementation is better than what I have shown here in
C++. Unfortunately, I don't know enough about Rust to talk about it's internals
in this case.&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;panic!&lt;/code&gt; and &lt;code&gt;{}&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;panic!&lt;/code&gt; is a macro (right now we can think of it as a function, but &lt;code&gt;!&lt;/code&gt; in Rust
is an indicator of a macro call) used for critical program errors.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;panic!&lt;/code&gt; receives an argument list similar to &lt;code&gt;printf&lt;/code&gt; known from other
programming languages, and &lt;code&gt;{}&lt;/code&gt; is used to print the values of any type (not
exactly, more on that later).&lt;/p&gt;
&lt;h2&gt;What's coming up?&lt;/h2&gt;
&lt;p&gt;In the next posts I plan to talk about:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;handling HTTP requests in different threads&lt;/li&gt;
&lt;li&gt;ownership and borrowing (the main characteristic of Rust that differentiates
  it from popular modern programming languages)&lt;/li&gt;
&lt;li&gt;creating structures&lt;/li&gt;
&lt;li&gt;methods&lt;/li&gt;
&lt;li&gt;traits&lt;/li&gt;
&lt;li&gt;expressions and statements&lt;/li&gt;
&lt;li&gt;and many, many more.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Other parts&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="proxy-server-in-rust-part-3.html"&gt;next post (part 3)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="proxy-server-in-rust-part-1.html"&gt;previous post (part 1)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="rust"></category><category term="foxy"></category></entry><entry><title>Proxy server in Rust (part 1)</title><link href="http://kele.github.io/en/proxy-server-in-rust-part-1.html" rel="alternate"></link><published>2017-06-17T00:00:00+02:00</published><updated>2017-06-17T00:00:00+02:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2017-06-17:/en/proxy-server-in-rust-part-1.html</id><summary type="html">&lt;p&gt;Learning Rust by writing a simple proxy server.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;What this is all about&lt;/h1&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;I'm constantly distracting myself. Very often I visit sites like Hacker News or
lobste.rs even though I don't have time to read the articles. As one can
imagine, it doesn't help very much with being productive. I don't really have
this problem when I'm busy and focused, but when I have 2-3 minutes to spare
(because the project is building, my map-reduce is running or I'm waiting for a
reply), my habit is to skim through every website that I find at least mildly
interesting.&lt;/p&gt;
&lt;p&gt;I've tried different Chrome extensions, changes in &lt;code&gt;/etc/hosts&lt;/code&gt; or blocking some
domains on my home router, but none of these were flexible enough for me so I
ended up working around them. This is where the idea of writing my own proxy
server came from. The list of features should include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;redirecting,&lt;/li&gt;
&lt;li&gt;time based blocking,&lt;/li&gt;
&lt;li&gt;delaying (if a site loads slowly, I tend to realize that I shouldn't be doing
  this),&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Why Rust?&lt;/h2&gt;
&lt;p&gt;The language I used the most was always C++. At work I'm using mostly Go now.
Although, the idea of having a strong compiler definitely speaks to me. That's
why I wanted to learn Rust. Also, a proxy server seems to be a project easy
enough that it won't distract me too much from learning the language itself, but
hard enough to see whether I like Rust or not.&lt;/p&gt;
&lt;h2&gt;What can you expect?&lt;/h2&gt;
&lt;p&gt;This is going to be a journal of my adventure with Rust. I have never ever used
this language, so it's not going to be a tutorial of &lt;strong&gt;how to write good Rust&lt;/strong&gt;,
but I'm definitely going to try my best to learn as much as possible and share
the knowledge. I have an idea what the borrow checking is about and I have some
experience with rich type systems (Hindley-Milner from OCaml), so I hope I won't
be lost completely. :)&lt;/p&gt;
&lt;h1&gt;Preparations&lt;/h1&gt;
&lt;h2&gt;Compiler&lt;/h2&gt;
&lt;p&gt;Instalation is very simple: &lt;a href="https://rustup.rs/"&gt;rustup.rs&lt;/a&gt;. Some of the Linux
distros are going to have Rust in their repositories already.&lt;/p&gt;
&lt;p&gt;For convenience, most of the operations (creating projects, building, running)
are done by using a tool called &lt;code&gt;cargo&lt;/code&gt;'. Please, do not forget to install it if
you're not using rustup.rs.&lt;/p&gt;
&lt;h2&gt;Documentation and other learning resources&lt;/h2&gt;
&lt;p&gt;There are lots of good materials for learning Rust. The primary official
document of the language and the standard library documentation can be both
found at &lt;a href="https://www.rust-lang.org/"&gt;rust-lang.org&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;My programming environment&lt;/h2&gt;
&lt;p&gt;VIM + &lt;a href="https://github.com/phildawes/racer"&gt;Racer&lt;/a&gt; +
&lt;a href="https://github.com/racer-rust/vim-racer"&gt;vim-racer&lt;/a&gt;. Racer is an
auto-completion tool for Rust.&lt;/p&gt;
&lt;h2&gt;Creating a new project&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cargo new --bin project
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This command creates a template of an executable  (&lt;code&gt;--bin&lt;/code&gt;) named &lt;code&gt;project&lt;/code&gt;.
What's interestinghere is that the project is going to be created under Git
versioning control system by default (nice gesture ;)).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cargo build&lt;/code&gt; builds the project. The default template is the well known &lt;strong&gt;Hello
World&lt;/strong&gt;.&lt;/p&gt;
&lt;h1&gt;The end of the first post&lt;/h1&gt;
&lt;p&gt;It's all for today. In the next post there will be some code, I promise! :)&lt;/p&gt;
&lt;h1&gt;Other parts&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="proxy-server-in-rust-part-2.html"&gt;next post (part 2)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="rust"></category><category term="foxy"></category></entry><entry><title>CIFAR10 classification summary</title><link href="http://kele.github.io/en/cifar10-classification-summary.html" rel="alternate"></link><published>2016-03-04T00:00:00+01:00</published><updated>2016-03-04T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-03-04:/en/cifar10-classification-summary.html</id><summary type="html">&lt;h1&gt;Problem description&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR10&lt;/a&gt; classification is a very popular problem among neural networks enthusiast. The main task is to map 32x32 RGB images to (disjoint) classes. This (simple) version of the problem differentiates 10 classes (hence the name).&lt;/p&gt;
&lt;p&gt;A list of best results for this problem can be found &lt;a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Problem description&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR10&lt;/a&gt; classification is a very popular problem among neural networks enthusiast. The main task is to map 32x32 RGB images to (disjoint) classes. This (simple) version of the problem differentiates 10 classes (hence the name).&lt;/p&gt;
&lt;p&gt;A list of best results for this problem can be found &lt;a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As one can guess, this problem is significantly harder than MNIST, both because of the input size and the nature of the images (two pictures of cats can be very different, but a digit always has roughly the same shape).&lt;/p&gt;
&lt;p&gt;The CIFAR10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. &lt;/p&gt;
&lt;h1&gt;Network architecture&lt;/h1&gt;
&lt;p&gt;Since the dataset is a collection of 2D images, using convolutional neural networks seem to be a good place to start. This is because of the fact that CNNs are able to learn to detect some local properties of the input, by looking at a patch of data at once. This is not only vital for doing any image processing work (i.e. edge detection), but it can greately decrease the size of the NN, since neurons used to detect a single feature share parameters (weights).&lt;/p&gt;
&lt;h1&gt;How the training is done?&lt;/h1&gt;
&lt;h2&gt;Technique&lt;/h2&gt;
&lt;p&gt;Stochastic gradient descent (with mini batches) is used as a standard learning technique.&lt;/p&gt;
&lt;h2&gt;Epochs&lt;/h2&gt;
&lt;p&gt;The training set is divided into epochs of a size of 40000 images, after each a validation set of size 10000 is used. The data is split into mini batches.&lt;/p&gt;
&lt;h2&gt;Mini batches&lt;/h2&gt;
&lt;p&gt;Mini batches of size 100 are used. Using less than that seems to be a bad idea, since we have 10 classes and we would like to see at least a few examples of each class in one mini batch. Using more than that might speed up the computation on GPUs, but because of the choice of the learning technique (SGD), it might actually take longer to learn (fewer steps).&lt;/p&gt;
&lt;h2&gt;Data preparation&lt;/h2&gt;
&lt;p&gt;The data is scaled and shifted to fit in [-1; +1] range.&lt;/p&gt;
&lt;h1&gt;Report&lt;/h1&gt;
&lt;h2&gt;Getting around 75% accuracy&lt;/h2&gt;
&lt;p&gt;This is a sample network architecture that is able to quickly learn to solve our problem achieving around 75% accuracy on the test dataset.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input layer&lt;/li&gt;
&lt;li&gt;2d Convolutional layer (128 filters of size 5x5, ReLu)&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;2d Convolutional layer (128 filters of size 5x5, ReLu)&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;Dropout layer (probability = 0.5)&lt;/li&gt;
&lt;li&gt;Dense layer (256 neurons, ReLu)&lt;/li&gt;
&lt;li&gt;Softmax layer (10 neurons)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This simple architecture deservers a short explanation.&lt;/p&gt;
&lt;p&gt;ReLu is used as the activation function for the obvious reasons (efficient computation, no vanishing gradient, etc.). At the moment of writing this report, it seems to be the most popular activation function for NNs.&lt;/p&gt;
&lt;p&gt;An affine (dense) layer is introduced near the end of the network for simplicity. Although, all-convolutional NNs are possible (&lt;a href="http://arxiv.org/abs/1412.6806"&gt;http://arxiv.org/abs/1412.6806&lt;/a&gt;), their design is a little more sophisticated.&lt;/p&gt;
&lt;p&gt;As for mitigating the risks of overfitting, early stopping with a validation set is used. The second tool helping to deal with this phenomena is the dropout.&lt;/p&gt;
&lt;h2&gt;Getting over 75% accuracy&lt;/h2&gt;
&lt;h3&gt;Techniques used to improve the learning process&lt;/h3&gt;
&lt;p&gt;The architecture mentioned in previous chapter is probably not suitable for getting statistically significant over 75% accuracy without a bit of luck.&lt;/p&gt;
&lt;p&gt;Since the network is not that small, there is a risk of overfitting. Besides dropout, weight decay (L2 regularization) and momentum are used.&lt;/p&gt;
&lt;p&gt;Learning rate decay is used as a standard approach to improve both the speed and the effectiveness of the process.&lt;/p&gt;
&lt;h3&gt;Architecture&lt;/h3&gt;
&lt;p&gt;This architecture together with mentioned improvements can be used to achieve 78% test accuracy within just 25 epochs of training. One epoch took around 15s on GeForce GTX 780 GPU, which sums up to less than 7 minutes of training.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input layer&lt;/li&gt;
&lt;li&gt;2d Convolutional layer (128 filters of size 5x5, ReLu)&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2d Convolutional layer (64 filters of size 5x5, ReLu)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dropout layer (probability = 0.5)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dense layer (800 neurons, ReLu)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Dropout layer (probability = 0.5)&lt;/li&gt;
&lt;li&gt;Dense layer (256 neurons, ReLu)&lt;/li&gt;
&lt;li&gt;Softmax layer (10 neurons)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It seems that keeping two big convolutional layers was not needed. On the other hand, introducing an additional affine layer helped achieving better accuracy. Adding more dropout layers seems to introduce too much noise to make the learning process efficient.&lt;/p&gt;
&lt;h3&gt;Hyperparameters&lt;/h3&gt;
&lt;p&gt;The hyperparamers were found by trial and error.&lt;/p&gt;
&lt;p&gt;The learning rate decay formula:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start: 0.01&lt;/li&gt;
&lt;li&gt;divide by 1.5 after 4000 mini batches&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Momentum: 0.9.&lt;/p&gt;
&lt;p&gt;Weight decay: 0.01.&lt;/p&gt;
&lt;h2&gt;Getting over 80% accuracy&lt;/h2&gt;
&lt;h3&gt;Data augmentation&lt;/h3&gt;
&lt;p&gt;Introducing random horizontal flip (mirror, left to right) improved the accuracy to over 80% after less than 60 epochs (with the same epoch computation time as before, 15 seconds).&lt;/p&gt;
&lt;h2&gt;Getting 81.72% accuracy&lt;/h2&gt;
&lt;p&gt;Data augmentation
Adding a random rotation between [-20; +20] degrees allowed to achieve 81.72% accuracy on the test dataset without increasing the learning time.&lt;/p&gt;
&lt;h1&gt;Implementation details&lt;/h1&gt;
&lt;p&gt;A lightweight library built on top of &lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt; called &lt;a href="https://github.com/Lasagne/Lasagne"&gt;Lasagne&lt;/a&gt; was used for the implementation. The source code is available here: &lt;a href="https://github.com/kele/cifar_recognition/"&gt;https://github.com/kele/cifar_recognition/&lt;/a&gt;. Using it is pretty straightforward and I highly recommend this as a base for any neural networks project.&lt;/p&gt;
&lt;h1&gt;Future work&lt;/h1&gt;
&lt;h2&gt;Deeper neural network&lt;/h2&gt;
&lt;p&gt;A deeper neural network could be used to improve the results. On the other hand, that might introduce even bigger risk of overfitting and greately increase the learning time.&lt;/p&gt;
&lt;h2&gt;Data augmentation&lt;/h2&gt;
&lt;p&gt;Data augmentation proved to be very helpful for solving the CIFAR10 problem. The solutions described in this report could take advantage of image transformations such as ZCA. Also, using slight shifts and rotations, or random crops of the image could be used to artificially enlarge the training dataset.&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;One can easily solve the CIFAR10 classification problem with a decent accuracy using widely available Python libraries. The only caveat is the fact that deep neural networks might require efficient, CUDA-capable GPUs to work (and learn) fast.&lt;/p&gt;</content></entry><entry><title>Using Lasagne to achieve over 75% accuracy on CIFAR10.</title><link href="http://kele.github.io/en/using-lasagne-to-achieve-over-75-accuracy-on-cifar10.html" rel="alternate"></link><published>2016-01-25T00:00:00+01:00</published><updated>2016-01-25T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-25:/en/using-lasagne-to-achieve-over-75-accuracy-on-cifar10.html</id><summary type="html">&lt;p&gt;This is the first report of my battle with the &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR10
classification&lt;/a&gt; problem.&lt;/p&gt;
&lt;p&gt;I've decided to use &lt;a href="http://lasagne.readthedocs.org/en/latest/"&gt;Lasagne&lt;/a&gt; which
is a ligthweight library build on top of
&lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's the source code I'll be talking about in this post:
&lt;a href="https://github.com/kele/cifar_recognition/tree/over75"&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;I don't do any data augmentation.&lt;/li&gt;
&lt;li&gt;This piece of …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;This is the first report of my battle with the &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR10
classification&lt;/a&gt; problem.&lt;/p&gt;
&lt;p&gt;I've decided to use &lt;a href="http://lasagne.readthedocs.org/en/latest/"&gt;Lasagne&lt;/a&gt; which
is a ligthweight library build on top of
&lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's the source code I'll be talking about in this post:
&lt;a href="https://github.com/kele/cifar_recognition/tree/over75"&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;I don't do any data augmentation.&lt;/li&gt;
&lt;li&gt;This piece of code was intended to get me familiarized with Lasagne.&lt;/li&gt;
&lt;li&gt;It achieves slighly over 75% accuracy and I think it's the peak for this
  design of the neural network.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;What is in my toolbox?&lt;/h1&gt;
&lt;p&gt;My network consists of both dense and convolutional layers. There's a good
reason to use the latter, since they might exploit the nature of our problem
(which is image classification). More on that can be read
&lt;a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/"&gt;here&lt;/a&gt;,
&lt;a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/"&gt;here&lt;/a&gt; and
&lt;a href="http://neuralnetworksanddeeplearning.com/chap6.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The main intution behind convolutional layers is as follows. We want to detect a
&lt;em&gt;local&lt;/em&gt; property of an image, i.e. an edge. We don't really care (for now) where
it is, we just want to be sure that it exists. There's no difference in
detecting an edge in the middle of an image or a few pixels to the right.
Because of that, it makes no sense to keep separate parameters (weights and
biases) for different neurons, just because they're looking in some other place
for the same thing.&lt;/p&gt;
&lt;p&gt;An additional benefit is the fact that since we're sharing the parameters, there
are less of them to find.&lt;/p&gt;
&lt;h1&gt;Architecture&lt;/h1&gt;
&lt;p&gt;How does the architecture look like?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input layer&lt;/li&gt;
&lt;li&gt;2d Convolutional layer (128 filters of size 5x5, ReLu)&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;2d Convolutional layer (128 filters of size 5x5, ReLu)&lt;/li&gt;
&lt;li&gt;2d MaxPool layer (pool size 2x2)&lt;/li&gt;
&lt;li&gt;Dropout layer (probability = 0.5)&lt;/li&gt;
&lt;li&gt;Dense layer (256 neurons, ReLu)&lt;/li&gt;
&lt;li&gt;Softmax layer (10 neurons)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;p&gt;With this architecture I've managed to achieve a little over 75% of accuracy
with around 2 hours of training (on my GT645&lt;strong&gt;M&lt;/strong&gt;, which is not a speed demon).&lt;/p&gt;
&lt;h1&gt;Roadmap&lt;/h1&gt;
&lt;p&gt;So, what can we do now?&lt;/p&gt;
&lt;h3&gt;Changing the network architecture&lt;/h3&gt;
&lt;p&gt;So far we can see that my network is pretty shallow. Maybe adding more filters
could help? Also, it might be helpful to put a dense ReLu layer between some
convolution layers. I'll have to experiment with these ideas.&lt;/p&gt;
&lt;h3&gt;Better learning techniques&lt;/h3&gt;
&lt;p&gt;This version of the code doesn't use &lt;strong&gt;weight decay&lt;/strong&gt; nor &lt;strong&gt;learning rate&lt;/strong&gt;
decay. The only enchancement is the &lt;strong&gt;momentum&lt;/strong&gt;. Both of the missing techniques
could be added easily.&lt;/p&gt;
&lt;p&gt;These techniques require some additional tuning, so it might be a
little time consuming to find the right parameters. It'd be a good idea to do
that as the last step, after picking a good network architecture.&lt;/p&gt;
&lt;h3&gt;Data augmentation&lt;/h3&gt;
&lt;p&gt;So far I haven't done anything with the input data at all.&lt;/p&gt;
&lt;p&gt;The following simple transformations come to my mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cropping the image at random&lt;/li&gt;
&lt;li&gt;horizontal flip&lt;/li&gt;
&lt;li&gt;rescaling&lt;/li&gt;
&lt;/ul&gt;</content><category term="neural networks"></category><category term="cifar"></category></entry><entry><title>Getting CUDA working on a laptop with two GPUs</title><link href="http://kele.github.io/en/getting-cuda-working-on-a-laptop-with-two-gpus.html" rel="alternate"></link><published>2016-01-18T00:00:00+01:00</published><updated>2016-01-18T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-18:/en/getting-cuda-working-on-a-laptop-with-two-gpus.html</id><summary type="html">&lt;p&gt;I had a lot of trouble setting up my laptop NVIDIA GPU with CUDA on Ubuntu
14.04. These steps might actually help somebody.&lt;/p&gt;
&lt;p&gt;First, download the &lt;a href="http://developer.nvidia.com/cuda-downloads"&gt;NVIDIA CUDA Toolkit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Remove all old NVIDIA-related drivers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get remove --purge nvidia*
sudo apt-get --purge remove xserver-xorg-video-nouveau
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Backup your &lt;code&gt;/etc/modprobe.d …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I had a lot of trouble setting up my laptop NVIDIA GPU with CUDA on Ubuntu
14.04. These steps might actually help somebody.&lt;/p&gt;
&lt;p&gt;First, download the &lt;a href="http://developer.nvidia.com/cuda-downloads"&gt;NVIDIA CUDA Toolkit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Remove all old NVIDIA-related drivers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get remove --purge nvidia*
sudo apt-get --purge remove xserver-xorg-video-nouveau
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Backup your &lt;code&gt;/etc/modprobe.d/blacklist.conf&lt;/code&gt; and make sure it contains these lines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;blacklist nouveau
blacklist lbm-nouveau
blacklist nvidia-173
blacklist nvidia-96
blacklist nvidia-current
blacklist nvidia-173-updates
blacklist nvidia-96-updates
&lt;span class="nb"&gt;alias&lt;/span&gt; nvidia nvidia_current_updates
&lt;span class="nb"&gt;alias&lt;/span&gt; nouveau off
&lt;span class="nb"&gt;alias&lt;/span&gt; lbm-nouveau off
options nouveau &lt;span class="nv"&gt;modeset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Add bumblebee and xorg-edgers repositories:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-add-repository ppa:bumblebee/stable -y
sudo add-apt-repository ppa:xorg-edgers/ppa -y
sudo apt-get update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo apt-get upgrade -y
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now it's time to install the CUDA toolkit (along with &lt;code&gt;nvidia-352&lt;/code&gt; drivers).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# This installs necessary headers.&lt;/span&gt;
sudo apt-get install linux-source &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo apt-get install linux-headers-&lt;span class="k"&gt;$(&lt;/span&gt;uname -r&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# USE THE REAL PACKAGE NAME BELOW&lt;/span&gt;
sudo dpkg -i cuda-repo-ubuntu1404-7-5-local_7.5-18_amd64.deb

sudo apt-get install cuda
sudo apt-get update
sudo apt-get dist-upgrade -y
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Install bumblebee (to have switchable GPUs).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install bumblebee bumblebee-nvidia virtualgl virtualgl-libs virtualgl-libs-ia32:i386 virtualgl-libs:i386
sudo usermod -a -G bumblebee &lt;span class="nv"&gt;$USER&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Edit &lt;code&gt;/etc/bumblebee/bumblebee.conf&lt;/code&gt; as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Change all occurences of &lt;code&gt;nvidia-current&lt;/code&gt; to &lt;code&gt;nvidia-352&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;After &lt;code&gt;Driver=&lt;/code&gt; insert &lt;code&gt;nvidia&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;After &lt;code&gt;KernelDriver=&lt;/code&gt; insert &lt;code&gt;nvidia-352&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;(if having trouble with optirun) uncomment the &lt;code&gt;BusID&lt;/code&gt; line and set it
  accordingly to what the comment above this line says.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Make sure that these lines are in &lt;code&gt;/etc/modprobe.d/bumblebee.conf&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;blacklist nvidia-352
blacklist nvidia-352-updates
blacklist nvidia-experimental-352

&lt;span class="nb"&gt;alias&lt;/span&gt; nvidia-uvm nvidia_352_uvm
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After &lt;code&gt;reboot&lt;/code&gt; everything should work fine. You can test it with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;optirun glxspheres64
&lt;span class="c1"&gt;# compare the performance with default GPU running the command above without optirun&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you need more help: &lt;a href="http://developer.download.nvidia.com/compute/cuda/7.5/Prod/docs/sidebar/CUDA_Installation_Guide_Linux.pdf"&gt;CUDA installation guide for Linux&lt;/a&gt;&lt;/p&gt;</content><category term="cuda"></category><category term="neural networks"></category></entry><entry><title>Setting up IPython with Git</title><link href="http://kele.github.io/en/setting-up-ipython-with-git.html" rel="alternate"></link><published>2016-01-17T00:00:00+01:00</published><updated>2016-01-17T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-17:/en/setting-up-ipython-with-git.html</id><summary type="html">&lt;p&gt;Since I've been annoyed by how IPython notebooks integrate with Git, I'd like
to share a solution for this problem.&lt;/p&gt;
&lt;p&gt;The description can be found here: &lt;a href="http://stackoverflow.com/a/25765194/1239545"&gt;http://stackoverflow.com/a/25765194/1239545&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;What it does is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it adds a hook for saving the notebook, which also saves a &lt;em&gt;pure&lt;/em&gt; version …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Since I've been annoyed by how IPython notebooks integrate with Git, I'd like
to share a solution for this problem.&lt;/p&gt;
&lt;p&gt;The description can be found here: &lt;a href="http://stackoverflow.com/a/25765194/1239545"&gt;http://stackoverflow.com/a/25765194/1239545&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;What it does is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it adds a hook for saving the notebook, which also saves a &lt;em&gt;pure&lt;/em&gt; version&lt;/li&gt;
&lt;li&gt;it suggests that you keep both the pure version and the notebook under version control&lt;/li&gt;
&lt;/ul&gt;</content></entry><entry><title>First post</title><link href="http://kele.github.io/en/first-post.html" rel="alternate"></link><published>2016-01-16T00:00:00+01:00</published><updated>2016-01-16T00:00:00+01:00</updated><author><name>kele</name></author><id>tag:kele.github.io,2016-01-16:/en/first-post.html</id><summary type="html">&lt;p&gt;First post.&lt;/p&gt;</summary><content type="html">&lt;p&gt;First post.&lt;/p&gt;</content></entry></feed>