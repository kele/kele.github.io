<!DOCTYPE html>
<html lang="en">

<head>
            <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="">
        <meta name="author" content="">


        <title>CIFAR10 classification summary</title>

            <link href="http://kele.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="kele.github.io Full Atom Feed" />
            <link href="http://kele.github.io/feeds/neural-networks.atom.xml" type="application/atom+xml" rel="alternate" title="kele.github.io Categories Atom Feed" />

        <!-- Bootstrap Core CSS -->
        <link href="./../theme/css/bootstrap.css" rel="stylesheet">

        <!-- Custom CSS -->
        <link href="./../theme/css/clean-blog.css" rel="stylesheet">

        <!-- Code highlight color scheme -->
            <link href="./../theme/css/code_blocks/darkly.css" rel="stylesheet">


        <!-- Custom Fonts -->
        <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
        <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
        <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->






	                <meta property="og:locale" content="pl_PL.utf8">
		<meta property="og:site_name" content="kele.github.io">

	<meta property="og:type" content="article">
	<meta property="article:author" content="">
	<meta property="og:url" content="./cifar10-classification-summary.html">
	<meta property="og:title" content="CIFAR10 classification summary">
	<meta property="og:description" content="">
	<meta property="og:image" content="./">
	<meta property="article:published_time" content="2016-03-04 00:00:00+01:00">
</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="./">kele.github.io</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
        <header class="intro-header" style="background-image: url('./../theme/images/header.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>CIFAR10 classification summary</h1>
                        <span class="meta">piÄ… 04 marzec 2016</span>
                        
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
    <!-- Post Content -->
    <article>
        <h1>Problem description</h1>
<p><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a> classification is a very popular problem among neural networks enthusiast. The main task is to map 32x32 RGB images to (disjoint) classes. This (simple) version of the problem differentiates 10 classes (hence the name).</p>
<p>A list of best results for this problem can be found <a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html">here</a></p>
<p>As one can guess, this problem is significantly harder than MNIST, both because of the input size and the nature of the images (two pictures of cats can be very different, but a digit always has roughly the same shape).</p>
<p>The CIFAR10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. </p>
<h1>Network architecture</h1>
<p>Since the dataset is a collection of 2D images, using convolutional neural networks seem to be a good place to start. This is because of the fact that CNNs are able to learn to detect some local properties of the input, by looking at a patch of data at once. This is not only vital for doing any image processing work (i.e. edge detection), but it can greately decrease the size of the NN, since neurons used to detect a single feature share parameters (weights).</p>
<h1>How the training is done?</h1>
<h2>Technique</h2>
<p>Stochastic gradient descent (with mini batches) is used as a standard learning technique.</p>
<h2>Epochs</h2>
<p>The training set is divided into epochs of a size of 40000 images, after each a validation set of size 10000 is used. The data is split into mini batches.</p>
<h2>Mini batches</h2>
<p>Mini batches of size 100 are used. Using less than that seems to be a bad idea, since we have 10 classes and we would like to see at least a few examples of each class in one mini batch. Using more than that might speed up the computation on GPUs, but because of the choice of the learning technique (SGD), it might actually take longer to learn (fewer steps).</p>
<h2>Data preparation</h2>
<p>The data is scaled and shifted to fit in [-1; +1] range.</p>
<h1>Report</h1>
<h2>Getting around 75% accuracy</h2>
<p>This is a sample network architecture that is able to quickly learn to solve our problem achieving around 75% accuracy on the test dataset.</p>
<ul>
<li>Input layer</li>
<li>2d Convolutional layer (128 filters of size 5x5, ReLu)</li>
<li>2d MaxPool layer (pool size 2x2)</li>
<li>2d Convolutional layer (128 filters of size 5x5, ReLu)</li>
<li>2d MaxPool layer (pool size 2x2)</li>
<li>Dropout layer (probability = 0.5)</li>
<li>Dense layer (256 neurons, ReLu)</li>
<li>Softmax layer (10 neurons)</li>
</ul>
<p>This simple architecture deservers a short explanation.</p>
<p>ReLu is used as the activation function for the obvious reasons (efficient computation, no vanishing gradient, etc.). At the moment of writing this report, it seems to be the most popular activation function for NNs.</p>
<p>An affine (dense) layer is introduced near the end of the network for simplicity. Although, all-convolutional NNs are possible (<a href="http://arxiv.org/abs/1412.6806">http://arxiv.org/abs/1412.6806</a>), their design is a little more sophisticated.</p>
<p>As for mitigating the risks of overfitting, early stopping with a validation set is used. The second tool helping to deal with this phenomena is the dropout.</p>
<h2>Getting over 75% accuracy</h2>
<h3>Techniques used to improve the learning process</h3>
<p>The architecture mentioned in previous chapter is probably not suitable for getting statistically significant over 75% accuracy without a bit of luck.</p>
<p>Since the network is not that small, there is a risk of overfitting. Besides dropout, weight decay (L2 regularization) and momentum are used.</p>
<p>Learning rate decay is used as a standard approach to improve both the speed and the effectiveness of the process.</p>
<h3>Architecture</h3>
<p>This architecture together with mentioned improvements can be used to achieve 78% test accuracy within just 25 epochs of training. One epoch took around 15s on GeForce GTX 780 GPU, which sums up to less than 7 minutes of training.</p>
<ul>
<li>Input layer</li>
<li>2d Convolutional layer (128 filters of size 5x5, ReLu)</li>
<li>2d MaxPool layer (pool size 2x2)</li>
<li><strong>2d Convolutional layer (64 filters of size 5x5, ReLu)</strong></li>
<li>2d MaxPool layer (pool size 2x2)</li>
<li><strong>Dropout layer (probability = 0.5)</strong></li>
<li><strong>Dense layer (800 neurons, ReLu)</strong></li>
<li>Dropout layer (probability = 0.5)</li>
<li>Dense layer (256 neurons, ReLu)</li>
<li>Softmax layer (10 neurons)</li>
</ul>
<p>It seems that keeping two big convolutional layers was not needed. On the other hand, introducing an additional affine layer helped achieving better accuracy. Adding more dropout layers seems to introduce too much noise to make the learning process efficient.</p>
<h3>Hyperparameters</h3>
<p>The hyperparamers were found by trial and error.</p>
<p>The learning rate decay formula:</p>
<ul>
<li>start: 0.01</li>
<li>divide by 1.5 after 4000 mini batches</li>
</ul>
<p>Momentum: 0.9.</p>
<p>Weight decay: 0.01.</p>
<h2>Getting over 80% accuracy</h2>
<h3>Data augmentation</h3>
<p>Introducing random horizontal flip (mirror, left to right) improved the accuracy to over 80% after less than 60 epochs (with the same epoch computation time as before, 15 seconds).</p>
<h2>Getting 81.72% accuracy</h2>
<p>Data augmentation
Adding a random rotation between [-20; +20] degrees allowed to achieve 81.72% accuracy on the test dataset without increasing the learning time.</p>
<h1>Implementation details</h1>
<p>A lightweight library built on top of <a href="http://deeplearning.net/software/theano/">Theano</a> called <a href="https://github.com/Lasagne/Lasagne">Lasagne</a> was used for the implementation. The source code is available here: <a href="https://github.com/kele/cifar_recognition/">https://github.com/kele/cifar_recognition/</a>. Using it is pretty straightforward and I highly recommend this as a base for any neural networks project.</p>
<h1>Future work</h1>
<h2>Deeper neural network</h2>
<p>A deeper neural network could be used to improve the results. On the other hand, that might introduce even bigger risk of overfitting and greately increase the learning time.</p>
<h2>Data augmentation</h2>
<p>Data augmentation proved to be very helpful for solving the CIFAR10 problem. The solutions described in this report could take advantage of image transformations such as ZCA. Also, using slight shifts and rotations, or random crops of the image could be used to artificially enlarge the training dataset.</p>
<h1>Conclusion</h1>
<p>One can easily solve the CIFAR10 classification problem with a decent accuracy using widely available Python libraries. The only caveat is the fact that deep neural networks might require efficient, CUDA-capable GPUs to work (and learn) fast.</p>
    </article>

    <hr>
        <div class="comments">
            <div id="disqus_thread"></div>
            <script>
                var disqus_config = function () {
                    this.page.url = 'http://kele.github.io/' + 'cifar10-classification-summary.html';
                    this.page.identifier = 'disqus-' + 'cifar10-classification-summary.html';
                };
                (function() {  // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = 'https://kele-github-io.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
        </div>
            </div>
        </div>
    </div>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                    </ul>
<p class="copyright text-muted">
    Blog powered by <a href="http://getpelican.com">Pelican</a>,
    which takes great advantage of <a href="http://python.org">Python</a>.
</p>                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="./../theme/js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="./../theme/js/bootstrap.min.js"></script>

        <!-- Custom Theme JavaScript -->
        <script src="./../theme/js/clean-blog.min.js"></script>


</body>

</html>